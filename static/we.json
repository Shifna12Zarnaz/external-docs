[{
  "version": "Changelog",
  "url": "http://localhost:1313/changelog/compage/1.0.0/compage-project-changelog/",
  "title": "changelog",
  "description": "",
  "searchKeyword": "",
  "content": "February Updates Feb 6, 2019\nLorem ipsum dolor sit amet, consetetur sadipscing elitr, sed diam nonumy eirmod tempor invidunt dolore magna aliquyam erat, sed diam voluptua. At vero eos et ustoLorem ipsum dolor sit amet, consetetur.\u0026quot;\nChanged Better support for using applying additional filters to posts_tax_query for categories for custom WordPress syncs\nReporting fine-tuning for speed improvements (up to 60% improvement in latency)\nReplaced login / registration pre-app screens with a cleaner design\nRemoved Removed an issue with the sync autolinker only interlinking selectively. Removed up an issue with prematurely logging out users March Updates Mar 6, 2019\nLorem ipsum dolor sit amet, consetetur sadipscing elitr, sed diam nonumy eirmod tempor invidunt dolore magna aliquyam erat, sed diam voluptua. At vero eos et ustoLorem ipsum dolor sit amet, consetetur.\u0026quot;\nAdded Some scheduled changelogs, tweets, and slack messages queued up this weekend and were not published on time. We fixed the issue and all delayed publications should be out. We now prioritize keywords over title and body so customers can more effectively influence search results Support form in the Assistant is now protected with reCaptcha to reduce spam reinitializeOnUrlChange added to the JavaScript API to improve support for pages with turbolinks Fixed Fixed an issue with the sync autolinker only interlinking selectively. Fixed up an issue with prematurely logging out users Changelog label Added Changed Depricated Removed Fixed Security Unreleased "
},{
  "version": "Changelog",
  "url": "http://localhost:1313/changelog/compage/1.0.1/compage-project-changelog/",
  "title": "changelog",
  "description": "",
  "searchKeyword": "",
  "content": "February Updates Feb 6, 2019\nLorem ipsum dolor sit amet, consetetur sadipscing elitr, sed diam nonumy eirmod tempor invidunt dolore magna aliquyam erat, sed diam voluptua. At vero eos et ustoLorem ipsum dolor sit amet, consetetur.\u0026quot;\nChanged Better support for using applying additional filters to posts_tax_query for categories for custom WordPress syncs\nReporting fine-tuning for speed improvements (up to 60% improvement in latency)\nReplaced login / registration pre-app screens with a cleaner design\nRemoved Removed an issue with the sync autolinker only interlinking selectively. Removed up an issue with prematurely logging out users March Updates Mar 6, 2019\nLorem ipsum dolor sit amet, consetetur sadipscing elitr, sed diam nonumy eirmod tempor invidunt dolore magna aliquyam erat, sed diam voluptua. At vero eos et ustoLorem ipsum dolor sit amet, consetetur.\u0026quot;\nAdded Some scheduled changelogs, tweets, and slack messages queued up this weekend and were not published on time. We fixed the issue and all delayed publications should be out. We now prioritize keywords over title and body so customers can more effectively influence search results Support form in the Assistant is now protected with reCaptcha to reduce spam reinitializeOnUrlChange added to the JavaScript API to improve support for pages with turbolinks Fixed Fixed an issue with the sync autolinker only interlinking selectively. Fixed up an issue with prematurely logging out users Changelog label Added Changed Depricated Removed Fixed Security Unreleased "
},{
  "version": "Changelog",
  "url": "http://localhost:1313/changelog/compage/1.0.0/",
  "title": "Compage",
  "description": "Compage project changelog.",
  "searchKeyword": "",
  "content": ""
},{
  "version": "Changelog",
  "url": "http://localhost:1313/changelog/compage/1.0.1/",
  "title": "Compage",
  "description": "Compage project changelog.",
  "searchKeyword": "",
  "content": ""
},{
  "version": "Changelog",
  "url": "http://localhost:1313/changelog/capten/1.0.0/",
  "title": "Capten",
  "description": "Capten project changelog.",
  "searchKeyword": "",
  "content": ""
},{
  "version": "Changelog",
  "url": "http://localhost:1313/changelog/capten/1.0.1/",
  "title": "Capten",
  "description": "Capten project changelog.",
  "searchKeyword": "",
  "content": ""
},{
  "version": "Changelog",
  "url": "http://localhost:1313/changelog/capten/1.0.0/capten-project-changelog/",
  "title": "changelog",
  "description": "",
  "searchKeyword": "",
  "content": "February Updates Feb 6, 2019\nLorem ipsum dolor sit amet, consetetur sadipscing elitr, sed diam nonumy eirmod tempor invidunt dolore magna aliquyam erat, sed diam voluptua. At vero eos et ustoLorem ipsum dolor sit amet, consetetur.\u0026quot;\nChanged Better support for using applying additional filters to posts_tax_query for categories for custom WordPress syncs\nReporting fine-tuning for speed improvements (up to 60% improvement in latency)\nReplaced login / registration pre-app screens with a cleaner design\nRemoved Removed an issue with the sync autolinker only interlinking selectively. Removed up an issue with prematurely logging out users March Updates Mar 6, 2019\nLorem ipsum dolor sit amet, consetetur sadipscing elitr, sed diam nonumy eirmod tempor invidunt dolore magna aliquyam erat, sed diam voluptua. At vero eos et ustoLorem ipsum dolor sit amet, consetetur.\u0026quot;\nAdded Some scheduled changelogs, tweets, and slack messages queued up this weekend and were not published on time. We fixed the issue and all delayed publications should be out. We now prioritize keywords over title and body so customers can more effectively influence search results Support form in the Assistant is now protected with reCaptcha to reduce spam reinitializeOnUrlChange added to the JavaScript API to improve support for pages with turbolinks Fixed Fixed an issue with the sync autolinker only interlinking selectively. Fixed up an issue with prematurely logging out users Changelog label Added Changed Depricated Removed Fixed Security Unreleased "
},{
  "version": "Changelog",
  "url": "http://localhost:1313/changelog/capten/1.0.1/capten-project-changelog/",
  "title": "changelog",
  "description": "",
  "searchKeyword": "",
  "content": "February Updates Feb 6, 2019\nLorem ipsum dolor sit amet, consetetur sadipscing elitr, sed diam nonumy eirmod tempor invidunt dolore magna aliquyam erat, sed diam voluptua. At vero eos et ustoLorem ipsum dolor sit amet, consetetur.\u0026quot;\nChanged Better support for using applying additional filters to posts_tax_query for categories for custom WordPress syncs\nReporting fine-tuning for speed improvements (up to 60% improvement in latency)\nReplaced login / registration pre-app screens with a cleaner design\nRemoved Removed an issue with the sync autolinker only interlinking selectively. Removed up an issue with prematurely logging out users March Updates Mar 6, 2019\nLorem ipsum dolor sit amet, consetetur sadipscing elitr, sed diam nonumy eirmod tempor invidunt dolore magna aliquyam erat, sed diam voluptua. At vero eos et ustoLorem ipsum dolor sit amet, consetetur.\u0026quot;\nAdded Some scheduled changelogs, tweets, and slack messages queued up this weekend and were not published on time. We fixed the issue and all delayed publications should be out. We now prioritize keywords over title and body so customers can more effectively influence search results Support form in the Assistant is now protected with reCaptcha to reduce spam reinitializeOnUrlChange added to the JavaScript API to improve support for pages with turbolinks Fixed Fixed an issue with the sync autolinker only interlinking selectively. Fixed up an issue with prematurely logging out users Changelog label Added Changed Depricated Removed Fixed Security Unreleased "
},{
  "version": "Compage",
  "url": "http://localhost:1313/compage/1.0.0/",
  "title": "Compage",
  "description": "Compage User Guide doc",
  "searchKeyword": "",
  "content": ""
},{
  "version": "Compage",
  "url": "http://localhost:1313/compage/1.0.1/",
  "title": "Compage",
  "description": "Compage User Guide doc",
  "searchKeyword": "",
  "content": ""
},{
  "version": "Compage",
  "url": "http://localhost:1313/compage/1.0.0/1-docs-structure/",
  "title": "Docs structure",
  "description": "",
  "searchKeyword": "",
  "content": "\nThis section is a high-level overview of how the Compage Documentation is structured. It will help you use the documentation more effectively by guiding you on where to look for specific information.\nThe Compage Documentation covers everything you need to know about Compage. It made up of four main sections which are:\nGetting started Contributing User Guide FAQs Introduction In the introduction section, you will find the three pages below. Head over to the Installation page to get the Compage up and running on your KinD cluster. The What is Compage? page summarizes the goals and features of the Compage project.\nWhat is Compage? Community Installation Contributing Compage is written in Golang, NodeJS and ReactJS and is Apache License - contributions are always welcome whether that means providing feedback, be it through GitHub, through the #feedback channel on our Discord server or testing existing and new features. All the relevant information below:\nContribute Guides We want to be able to give Compage users the tips and guidance necessary to be able to get the most value from the tool as quickly as possible. That\u0026rsquo;s why we will be continuously adding and updating informative guides and series in which try to relay valuable and actionable advice.\nHow to use Compage FAQs Find all the answers to all the Compage related questions you might have. Feel free to reach out via the #feedback channel on Discord to request the inclusion of additional questions.\nFAQs "
},{
  "version": "Compage",
  "url": "http://localhost:1313/compage/1.0.1/1-docs-structure/",
  "title": "Docs structure",
  "description": "",
  "searchKeyword": "",
  "content": "\nThis section is a high-level overview of how the Compage Documentation is structured. It will help you use the documentation more effectively by guiding you on where to look for specific information.\nThe Compage Documentation covers everything you need to know about Compage. It made up of four main sections which are:\nGetting started Contributing User Guide FAQs Introduction In the introduction section, you will find the three pages below. Head over to the Installation page to get the Compage up and running on your KinD cluster. The What is Compage? page summarizes the goals and features of the Compage project.\nWhat is Compage? Community Installation Contributing Compage is written in Golang, NodeJS and ReactJS and is Apache License - contributions are always welcome whether that means providing feedback, be it through GitHub, through the #feedback channel on our Discord server or testing existing and new features. All the relevant information below:\nContribute Guides We want to be able to give Compage users the tips and guidance necessary to be able to get the most value from the tool as quickly as possible. That\u0026rsquo;s why we will be continuously adding and updating informative guides and series in which try to relay valuable and actionable advice.\nHow to use Compage FAQs Find all the answers to all the Compage related questions you might have. Feel free to reach out via the #feedback channel on Discord to request the inclusion of additional questions.\nFAQs "
},{
  "version": "Compage",
  "url": "http://localhost:1313/compage/1.0.0/5-guides/1-how-to-use-compage/",
  "title": "How to use Compage",
  "description": "",
  "searchKeyword": "",
  "content": "End users of the Compage are developers in team. A developer as a user\nLogs in to the compage using his/her GitHub credentials. He/she needs to provide permissions for the Compage GitHub App to create repositories on his/her behalf, commit generated code to the repositories. Selects from existing projects or creates a new project from the dialog box presented. A compage project has a one-to-one relationship with GitHub repository. The compage project\u0026rsquo;s connected GitHub repository can contain all the generated source code for all the nodes created on drawing panel. Compage follows monorepo method, all connected microservices in single git repository. Uses drawing canvas to create nodes and configure one by one using forms after double-clicking on nodes. At last, he/she saves the project and hits Generate Code button. The code will be generated and saved to connected GitHub repository for that project. Uses same panel to add more microservices(nodes) or modify existing microservices. When the code is generated, version is locked till that point and any change made post code-generation till next code-generation is part of next version. User\u0026rsquo;s can have at most 10 versions per project as of now. Moving between versions is not yet supported. Create a node Create an edge "
},{
  "version": "Compage",
  "url": "http://localhost:1313/compage/1.0.1/5-guides/1-how-to-use-compage/",
  "title": "How to use Compage",
  "description": "",
  "searchKeyword": "",
  "content": "End users of the Compage are developers in team. A developer as a user\nLogs in to the compage using his/her GitHub credentials. He/she needs to provide permissions for the Compage GitHub App to create repositories on his/her behalf, commit generated code to the repositories. Selects from existing projects or creates a new project from the dialog box presented. A compage project has a one-to-one relationship with GitHub repository. The compage project\u0026rsquo;s connected GitHub repository can contain all the generated source code for all the nodes created on drawing panel. Compage follows monorepo method, all connected microservices in single git repository. Uses drawing canvas to create nodes and configure one by one using forms after double-clicking on nodes. At last, he/she saves the project and hits Generate Code button. The code will be generated and saved to connected GitHub repository for that project. Uses same panel to add more microservices(nodes) or modify existing microservices. When the code is generated, version is locked till that point and any change made post code-generation till next code-generation is part of next version. User\u0026rsquo;s can have at most 10 versions per project as of now. Moving between versions is not yet supported. Create a node Create an edge "
},{
  "version": "Compage",
  "url": "http://localhost:1313/compage/1.0.0/5-guides/2-create-services/",
  "title": "Creating MicroServices",
  "description": "",
  "searchKeyword": "",
  "content": "A node in Compage represents a microservice from developers perspective.\nDevelopers can drag nodes to canvas after logging into Compage and creating/selecting project. [diagram] Once the node is dragged and dropped, developer needs to add more properties to it. A dialog box is opened after double-clicking on the node. Compage supports REST protocol as of now. That means, Code for REST servers and REST clients can be generated by Compage. There are two ways to create REST servers as of now. OpenAPI generator templates Compage managed templates Supported Languages by OpenApi generator templates\nGo (go-server, go-gin-server, go-echo-server) Java (java-play-framework,java-micronaut-server,java-undertow-server) JavaScript (nodejs-express-server) TypeScript (typescript-node,typescript-axios) Ruby (ruby-on-rails,ruby-sinatra) Python (python-flask) Supported Languages by Compage managed templates\nGo (go-gin framework) Rust (in progress) Now, based on your choice, framework needs to be selected.\nYou have to add port for Compage managed templates but for OpenApi Generator templates, you don\u0026rsquo;t have to supply it as it\u0026rsquo;s taken automatically. For OpenApi Generator templates, you have to upload a valid OpenApi specification file. After adding all the properties to the node, you can create another node and follow the same steps to add property to it. If you want to create connection between nodes, you can drag from source node to destination node. "
},{
  "version": "Compage",
  "url": "http://localhost:1313/compage/1.0.1/5-guides/2-create-services/",
  "title": "Creating MicroServices",
  "description": "",
  "searchKeyword": "",
  "content": "A node in Compage represents a microservice from developers perspective.\nDevelopers can drag nodes to canvas after logging into Compage and creating/selecting project. [diagram] Once the node is dragged and dropped, developer needs to add more properties to it. A dialog box is opened after double-clicking on the node. Compage supports REST protocol as of now. That means, Code for REST servers and REST clients can be generated by Compage. There are two ways to create REST servers as of now. OpenAPI generator templates Compage managed templates Supported Languages by OpenApi generator templates\nGo (go-server, go-gin-server, go-echo-server) Java (java-play-framework,java-micronaut-server,java-undertow-server) JavaScript (nodejs-express-server) TypeScript (typescript-node,typescript-axios) Ruby (ruby-on-rails,ruby-sinatra) Python (python-flask) Supported Languages by Compage managed templates\nGo (go-gin framework) Rust (in progress) Now, based on your choice, framework needs to be selected.\nYou have to add port for Compage managed templates but for OpenApi Generator templates, you don\u0026rsquo;t have to supply it as it\u0026rsquo;s taken automatically. For OpenApi Generator templates, you have to upload a valid OpenApi specification file. After adding all the properties to the node, you can create another node and follow the same steps to add property to it. If you want to create connection between nodes, you can drag from source node to destination node. "
},{
  "version": "Compage",
  "url": "http://localhost:1313/compage/1.0.0/2-overview/",
  "title": "Overview",
  "description": "",
  "searchKeyword": "",
  "content": "\nCompage is the open-source project by IntelOps.\nCompage was pictured in mind after facing troubles while bootstrapping new projects and adding integrations of standard practices.\nAs a project, Compage\u0026rsquo;s goal is to help developers spend less time in bootstrapping projects and follow standard practices all the time. What\u0026rsquo;s offered from this project is that you can draw diagrams, create connections between the nodes(microservices) and get the skeleton projects generated which follow standard cloud-native practices.\nCompage is a low-code framework to develop Rest APIs, gRPC, dRPC, GraphQL APIs, WebSockets, Micro-services, FaaS, Temporal workloads, IoT and edge services, K8s controllers, K8s CRDs, K8s custom APIs, K8s Operators, K8s hooks, etc. with visual coding and by automatically applying best practice methods like software supply chain security measures, SBOM, openAPI, cloud-events, vulnerability reports, etc. auto generate code after defining requirements in UI as architecture diagram.\nDraw the requirements for backend workloads, and then auto generate code, customize it and maintain it by using Compage.\nOur goal is to support both auto-generate code and import existing code. Let\u0026rsquo;s see how far we can go with importing existing code support. One step at a time!\nProblem statement: Problems with many of the current low-code platforms -\nSingle programming language support only. Vendor Lock-in Infrastructure if you want to choose their cloud hosting. No proper support or automation for self-hosting and also lots of dependencies on the low-code/no-code tool itself to run it on your infrastructure. No Zero-Vendor Lock-in platform to generate cloud-native. friendly backend source code, especially for Rest APIs, gRPC, WebSockets, etc. in any programming language and framework we want. Non-availability of a very opinionated development process \u0026amp; management of infrastructure. Not compatible to cloud-native, especially for self-hosting K8s environment. Not invoking standards like openAPI, Event-driven, software supply chain security, secure container builds, microservices, etc. Not supporting modern tech stack and no feasibility to adopt new tech stack dynamically. No bi-directional code management (export, import and manage). No easy UX to make any level of developer to learn, adopt and implement development process for K8s ecosystem for cloud-native world. and the list can go on **(please let us know what more you can think of, we will try to solve those problems for you) ** Solution: Compage An opensource tool that runs on your k8s cluster (can be deployed once per team), helps to visually develop backend workloads for cloud-native \u0026amp; K8s :- Easy to adopt \u0026amp; use UI/UX. GitHub\u0026rsquo;s integration, container build tools, cosign, etc. Equipped with diagramming library to define the project requirements by drawing the flow of backend workloads. Annotations, labels, tags, versioning, etc. can be defined within the diagram using forms. Select the programming language and framework you prefer (support for each programming language and framework will be added one by one); first priority is GoLang and Rust. Frameworks can be configured as plug-ins. Auto generate code for backend workloads like Rest API, gRPC, dRPC, GraphQL, WebSockets, Microservices, FaaS, Temporal workloads, IoT and edge services, K8s controllers, K8s CRDs, K8s custom APIs, K8s Operators, K8s hooks, etc. (for now support will be for golang and then Rust as priority, followed by Python, C, Carbon, Node.js, Dart, Deno, etc. Community contribution will help us to achieve more support) Auto generate the backend code, based on requirements defined via diagram \u0026amp; forms Auto generate the endpoint configs to be able to use with API gateways \u0026amp; service-mesh environments like Kong, Tyk, Easegress, Istio, Linkerd, Kuma, Ngnix, Cilium tools, Calico, etc. Easy plug-ins by supporting tools like Ory Hydra, Kratos, Keto, OathKeeper, KeyCloak, Gluu, Janssen, Cerbos, Open Policy Agent, OAuth, OIDC, FIDO, SAML, Dex, MFA, Passwordless, etc. Auto build containers as multi-stage and/or distroless to make them secure, portable and optimal. Automatically take care of all git processes like tagging, versioning, commits, PRs, etc. Automatically enforce software supply chain security process like signing the source code for integrity and generating immutable ledger logs, generating SBOM, generating vulnerability report, and also generate configurations to auto verify, validate \u0026amp; control the source code integrity and container image integrity for deployments, etc. in K8s env. Automatically convert backend application related environment variables\u0026rsquo; content to configmaps, secrets, etc. to make the generated backend compatible to K8s of any flavor (K8s, K3s, TalOS, etc.) and also auto configs to support integration with Vault, cert-manager, external secrets, sealed secrets \u0026amp; Venafi tools for TLS/SSL and secrets management. Slowly add support for ML development \u0026amp; ML frameworks to make it easy to develop ML applications that will run on Kubernetes. Automatically manage generated code for by auto creating the services catalog \u0026amp; their visualization by versioning and integrations, and also git repo observability. Please suggest what you would like to add as features. Current features in compage An opensource tool that runs on your k8s cluster (mostly a local cluster running on developer\u0026rsquo;s machine), helps to visually develop backend workloads for cloud-native \u0026amp; K8s. Easy to adopt \u0026amp; use UI. GitHub\u0026rsquo;s integration for authentication, container build tools, cosign, etc. Equipped with diagramming library to define the project requirements by drawing the flow of backend workloads. Annotations, labels, tags, versioning, etc. can be defined within the diagram using forms. Auto generate code for backend workloads like Rest API. Auto generate the backend code, based on requirements defined via diagram \u0026amp; forms. Auto build containers as multi-stage and/or distro-less to make them secure, portable and optimal. Automatically take care of all git processes like tagging, versioning, commits, PRs, etc. Automatically enforce software supply chain security process like generating cosign configuration in GitHub actions for generated source code for the diagrams drawn, generating deepsource configurations, generating configurations for deployments, services etc. in K8s env. Can be deployed directly with docker images or via Helm chart. Helm chart is the tested and preferred way. Even if you are deploying compage with docker images, you still need K8s cluster access to persist project and user data in etcd as CRs. Languages supported: OpenApi Generator based templates (REST services)\nGoLang Java Python JavaScript Ruby we would like to add more support to different languages. Please feel free to suggest. Compage managed templates (REST)\nGo Rust (in progress) Support of different programming languages, protocols and frameworks will be added one by one with community contribution.\nArchitecture Compage runs on any K8s cluster. Compage uses K8s custom resource as a store for projects and users. Compage currently has a support for Login with Github. Once user logs into the Compage, user can create projects. The information of projects created on Compage is stored in K8s and code generated by Compage is stored on GitHub.\nWhen user tries to log in to Compage, user is redirected to GitHub for login and asked for permissions to access repository. Once user provides permissions, user logs into the compage. A User CR will be created post user signs into the Compage along with the GitHub token retrieved by the earlier process.\nUser now needs to create a project before he could use the Canvas to draw diagrams. When the project is created in Compage, a project CR is created on K8s cluster(where your Compage is running). This process also creates a repository on GitHub and creates a .compage directory in it. As Compage makes use of aws diagram-maker, the configuration of the canvas can be exported to json. We can redraw the components on canvas using that json. Compage stores that json under .compage directory in config.json file. On every click of Save project, this file is updated in GitHub repository with the latest state of canvas.\nCompage has 3 components: core, app and ui.\ncore This is a Go component and acts as code generator for the configurations passed. This component considers the configuration passed from app and runs it on the templates. This component is a gRPC server to app component and streams the generated code back to app. Currently, it supports REST protocol and two types of REST templates are supported as of now. Compage managed templates The Compage managed templates are git submodules in the core component. If you want to support more frameworks or languages, you have to add the template in a separate repository and import it as submodule in this project. The current template for Go is a separate repository - https://github.com/intelops/compage-template-go.git OpenApi Generator templates app This is a NodeJs component and is responsible for authentication with GitHub and all the GitHub related operations. This component is a REST server to ui component and also a gRPC client to core. Further additions of other logins and GitHub operations will be done in this component. ui This is a ReactJs component and has an integration with aws diagram-maker for canvas. User draws diagram and the json created out of it is used to generate the code. "
},{
  "version": "Compage",
  "url": "http://localhost:1313/compage/1.0.1/2-overview/",
  "title": "Overview",
  "description": "",
  "searchKeyword": "",
  "content": "\nCompage is the open-source project by IntelOps.\nCompage was pictured in mind after facing troubles while bootstrapping new projects and adding integrations of standard practices.\nAs a project, Compage\u0026rsquo;s goal is to help developers spend less time in bootstrapping projects and follow standard practices all the time. What\u0026rsquo;s offered from this project is that you can draw diagrams, create connections between the nodes(microservices) and get the skeleton projects generated which follow standard cloud-native practices.\nCompage is a low-code framework to develop Rest APIs, gRPC, dRPC, GraphQL APIs, WebSockets, Micro-services, FaaS, Temporal workloads, IoT and edge services, K8s controllers, K8s CRDs, K8s custom APIs, K8s Operators, K8s hooks, etc. with visual coding and by automatically applying best practice methods like software supply chain security measures, SBOM, openAPI, cloud-events, vulnerability reports, etc. auto generate code after defining requirements in UI as architecture diagram.\nDraw the requirements for backend workloads, and then auto generate code, customize it and maintain it by using Compage.\nOur goal is to support both auto-generate code and import existing code. Let\u0026rsquo;s see how far we can go with importing existing code support. One step at a time!\nProblem statement: Problems with many of the current low-code platforms -\nSingle programming language support only. Vendor Lock-in Infrastructure if you want to choose their cloud hosting. No proper support or automation for self-hosting and also lots of dependencies on the low-code/no-code tool itself to run it on your infrastructure. No Zero-Vendor Lock-in platform to generate cloud-native. friendly backend source code, especially for Rest APIs, gRPC, WebSockets, etc. in any programming language and framework we want. Non-availability of a very opinionated development process \u0026amp; management of infrastructure. Not compatible to cloud-native, especially for self-hosting K8s environment. Not invoking standards like openAPI, Event-driven, software supply chain security, secure container builds, microservices, etc. Not supporting modern tech stack and no feasibility to adopt new tech stack dynamically. No bi-directional code management (export, import and manage). No easy UX to make any level of developer to learn, adopt and implement development process for K8s ecosystem for cloud-native world. and the list can go on **(please let us know what more you can think of, we will try to solve those problems for you) ** Solution: Compage An opensource tool that runs on your k8s cluster (can be deployed once per team), helps to visually develop backend workloads for cloud-native \u0026amp; K8s :- Easy to adopt \u0026amp; use UI/UX. GitHub\u0026rsquo;s integration, container build tools, cosign, etc. Equipped with diagramming library to define the project requirements by drawing the flow of backend workloads. Annotations, labels, tags, versioning, etc. can be defined within the diagram using forms. Select the programming language and framework you prefer (support for each programming language and framework will be added one by one); first priority is GoLang and Rust. Frameworks can be configured as plug-ins. Auto generate code for backend workloads like Rest API, gRPC, dRPC, GraphQL, WebSockets, Microservices, FaaS, Temporal workloads, IoT and edge services, K8s controllers, K8s CRDs, K8s custom APIs, K8s Operators, K8s hooks, etc. (for now support will be for golang and then Rust as priority, followed by Python, C, Carbon, Node.js, Dart, Deno, etc. Community contribution will help us to achieve more support) Auto generate the backend code, based on requirements defined via diagram \u0026amp; forms Auto generate the endpoint configs to be able to use with API gateways \u0026amp; service-mesh environments like Kong, Tyk, Easegress, Istio, Linkerd, Kuma, Ngnix, Cilium tools, Calico, etc. Easy plug-ins by supporting tools like Ory Hydra, Kratos, Keto, OathKeeper, KeyCloak, Gluu, Janssen, Cerbos, Open Policy Agent, OAuth, OIDC, FIDO, SAML, Dex, MFA, Passwordless, etc. Auto build containers as multi-stage and/or distroless to make them secure, portable and optimal. Automatically take care of all git processes like tagging, versioning, commits, PRs, etc. Automatically enforce software supply chain security process like signing the source code for integrity and generating immutable ledger logs, generating SBOM, generating vulnerability report, and also generate configurations to auto verify, validate \u0026amp; control the source code integrity and container image integrity for deployments, etc. in K8s env. Automatically convert backend application related environment variables\u0026rsquo; content to configmaps, secrets, etc. to make the generated backend compatible to K8s of any flavor (K8s, K3s, TalOS, etc.) and also auto configs to support integration with Vault, cert-manager, external secrets, sealed secrets \u0026amp; Venafi tools for TLS/SSL and secrets management. Slowly add support for ML development \u0026amp; ML frameworks to make it easy to develop ML applications that will run on Kubernetes. Automatically manage generated code for by auto creating the services catalog \u0026amp; their visualization by versioning and integrations, and also git repo observability. Please suggest what you would like to add as features. Current features in compage An opensource tool that runs on your k8s cluster (mostly a local cluster running on developer\u0026rsquo;s machine), helps to visually develop backend workloads for cloud-native \u0026amp; K8s. Easy to adopt \u0026amp; use UI. GitHub\u0026rsquo;s integration for authentication, container build tools, cosign, etc. Equipped with diagramming library to define the project requirements by drawing the flow of backend workloads. Annotations, labels, tags, versioning, etc. can be defined within the diagram using forms. Auto generate code for backend workloads like Rest API. Auto generate the backend code, based on requirements defined via diagram \u0026amp; forms. Auto build containers as multi-stage and/or distro-less to make them secure, portable and optimal. Automatically take care of all git processes like tagging, versioning, commits, PRs, etc. Automatically enforce software supply chain security process like generating cosign configuration in GitHub actions for generated source code for the diagrams drawn, generating deepsource configurations, generating configurations for deployments, services etc. in K8s env. Can be deployed directly with docker images or via Helm chart. Helm chart is the tested and preferred way. Even if you are deploying compage with docker images, you still need K8s cluster access to persist project and user data in etcd as CRs. Languages supported: OpenApi Generator based templates (REST services)\nGoLang Java Python JavaScript Ruby we would like to add more support to different languages. Please feel free to suggest. Compage managed templates (REST)\nGo Rust (in progress) Support of different programming languages, protocols and frameworks will be added one by one with community contribution.\nArchitecture Compage runs on any K8s cluster. Compage uses K8s custom resource as a store for projects and users. Compage currently has a support for Login with Github. Once user logs into the Compage, user can create projects. The information of projects created on Compage is stored in K8s and code generated by Compage is stored on GitHub.\nWhen user tries to log in to Compage, user is redirected to GitHub for login and asked for permissions to access repository. Once user provides permissions, user logs into the compage. A User CR will be created post user signs into the Compage along with the GitHub token retrieved by the earlier process.\nUser now needs to create a project before he could use the Canvas to draw diagrams. When the project is created in Compage, a project CR is created on K8s cluster(where your Compage is running). This process also creates a repository on GitHub and creates a .compage directory in it. As Compage makes use of aws diagram-maker, the configuration of the canvas can be exported to json. We can redraw the components on canvas using that json. Compage stores that json under .compage directory in config.json file. On every click of Save project, this file is updated in GitHub repository with the latest state of canvas.\nCompage has 3 components: core, app and ui.\ncore This is a Go component and acts as code generator for the configurations passed. This component considers the configuration passed from app and runs it on the templates. This component is a gRPC server to app component and streams the generated code back to app. Currently, it supports REST protocol and two types of REST templates are supported as of now. Compage managed templates The Compage managed templates are git submodules in the core component. If you want to support more frameworks or languages, you have to add the template in a separate repository and import it as submodule in this project. The current template for Go is a separate repository - https://github.com/intelops/compage-template-go.git OpenApi Generator templates app This is a NodeJs component and is responsible for authentication with GitHub and all the GitHub related operations. This component is a REST server to ui component and also a gRPC client to core. Further additions of other logins and GitHub operations will be done in this component. ui This is a ReactJs component and has an integration with aws diagram-maker for canvas. User draws diagram and the json created out of it is used to generate the code. "
},{
  "version": "Compage",
  "url": "http://localhost:1313/compage/1.0.0/5-guides/3-configure-services/",
  "title": "Declaring MicroServices Requirements",
  "description": "",
  "searchKeyword": "",
  "content": "An edge in Compage represents a connection from source microservice to destination service. Source microservice is a server here, and destination microservice is a client.\nIf you want to create connection between nodes, you can drag from source node to destination node. You can add properties to an edge too by double-clicking on it. You may have to select the edge and then double-click on it. The properties for the edge are just name and port (which is by default selected). Once the name is added, the edge gets renamed to that name. "
},{
  "version": "Compage",
  "url": "http://localhost:1313/compage/1.0.1/5-guides/3-configure-services/",
  "title": "Declaring MicroServices Requirements",
  "description": "",
  "searchKeyword": "",
  "content": "An edge in Compage represents a connection from source microservice to destination service. Source microservice is a server here, and destination microservice is a client.\nIf you want to create connection between nodes, you can drag from source node to destination node. You can add properties to an edge too by double-clicking on it. You may have to select the edge and then double-click on it. The properties for the edge are just name and port (which is by default selected). Once the name is added, the edge gets renamed to that name. "
},{
  "version": "Compage",
  "url": "http://localhost:1313/compage/1.0.0/3-installation/",
  "title": "Installation",
  "description": "",
  "searchKeyword": "",
  "content": "This document covers about how to set up Compage on your local with helm charts and Compage will be exposed through NodePort service to the outer world. When you deploy on the server, you have to expose the ui service using LoadBalancer service type or need to create an ingress.\nCreate a KinD cluster Make sure you have access to Kubernetes cluster along with a capability to install a namespaced scope CRD to your cluster. You can create a KinD cluster as explained here, in cluster creation section.\nRegister an app on GitHub To run Compage (on your local or on the server), you have to first set up GitHub app.\nRegister a new app on GitHub to retrieve clientId and clientSecret by following steps given on this link - https://docs.github.com/en/apps/creating-github-apps/creating-github-apps/creating-a-github-app. Update the clientId and clientSecret in values.yaml like below. githubApp: # update below value cluster\u0026#39;s node ip and with port specified here (.Values.ui.service.nodePort) redirectURI: \u0026#34;http://localhost:32222/login\u0026#34; clientId: \u0026#34;XXXXXXXX\u0026#34; clientSecret: \u0026#34;XXXXXXXX\u0026#34; ui: compageApp: # update below value cluster\u0026#39;s node ip and with port specified here (.Values.app.service.nodePort) serverUrl: http://localhost:31111 Create a namespace Currently, the compage namespace is made hard-coded but in-future, it will be completely configurable.\nkubectl create ns compage kubectl config set-context --current --namespace=compage Install the latest version from GitHub helm repository. Fire below set of commands and install the compage on your KinD cluster running locally.\nBefore this, you will have to create a docker image for ui component. As this is a UI component and commands in Dockerfile use below CONFIG values\nREACT_APP_GITHUB_APP_CLIENT_ID REACT_APP_GITHUB_APP_REDIRECT_URI REACT_APP_COMPAGE_APP_SERVER_URL to create it, you will have to use your configurations and create a docker image using below commands (run them from base folder of compage)\nTAG_NAME=\u0026#34;{version you are installing so that it will be automatically taken.}\u0026#34; UI_IMAGE=\u0026#34;ghcr.io/intelops/compage/ui:$TAG_NAME\u0026#34; # Assuming this is the name of your kind cluster CLUSTER_NAME=compage # create docker image for ui docker build -t $UI_IMAGE --network host ui/ kind load docker-image --name $CLUSTER_NAME $UI_IMAGE Once you are done with above commands, kindly run below set of commands.\nhelm repo remove intelops helm repo add \u0026#34;intelops\u0026#34; \u0026#34;https://raw.githubusercontent.com/intelops/compage/main/charts\u0026#34; helm install compage intelops/compage --values charts/compage/values.yaml kubectl get pods -n compage kubectl wait --for=condition=ready pod -l app.kubernetes.io/name=compage-ui kubectl wait --for=condition=ready pod -l app.kubernetes.io/name=compage-core kubectl wait --for=condition=ready pod -l app.kubernetes.io/name=compage-app Go to http://localhost:32222 Uninstall Simply, delete the cluster created above using kind delete cluster --name compage. If that\u0026rsquo;s not possible, delete the namespace kubectl delete ns compage\n"
},{
  "version": "Compage",
  "url": "http://localhost:1313/compage/1.0.1/3-installation/",
  "title": "Installation",
  "description": "",
  "searchKeyword": "",
  "content": "This document covers about how to set up Compage on your local with helm charts and Compage will be exposed through NodePort service to the outer world. When you deploy on the server, you have to expose the ui service using LoadBalancer service type or need to create an ingress.\nCreate a KinD cluster Make sure you have access to Kubernetes cluster along with a capability to install a namespaced scope CRD to your cluster. You can create a KinD cluster as explained here, in cluster creation section.\nRetrieve KinD cluster Node IP # retrieves nodes ip [tested on single node cluster] $KIND_NODE_IP=$(kubectl get nodes -o wide --no-headers | awk -v OFS=\u0026#39;\\t\u0026#39; \u0026#39;{print $6}\u0026#39;) Update KinD node ip in /etc/hosts. $KIND_NODE_IP (retrieved by above command) www.mycompage.dev You can choose your choice of url above. www.mycompage.dev is dummy here. Please make sure that you are using same urls in GitHub app as well(redirect url etc.). Register an app on GitHub To run Compage (on your local or on the server), you have to first set up GitHub app.\nRegister a new app on GitHub to retrieve clientId and clientSecret by following steps given on this link - https://docs.github.com/en/apps/creating-github-apps/creating-github-apps/creating-a-github-app. Update the clientId and clientSecret in values.yaml like below. githubApp: # update below value cluster\u0026#39;s node ip and with port specified here (.Values.ui.service.nodePort) redirectURI: \u0026#34;http://www.mycompage.dev:32222/login\u0026#34; clientId: \u0026#34;XXXXXXXX\u0026#34; clientSecret: \u0026#34;XXXXXXXX\u0026#34; ui: compageApp: # update below value cluster\u0026#39;s node ip and with port specified here (.Values.app.service.nodePort) serverUrl: http://www.mycompage.dev:31111 Create a namespace Currently, the compage namespace is made hard-coded but in-future, it will be completely configurable.\nkubectl create ns compage kubectl config set-context --current --namespace=compage Install the latest version from GitHub helm repository. Fire below set of commands and install the compage on your KinD cluster running locally.\nBefore this, you will have to create a docker image for ui component. As this is a UI component and commands in Dockerfile use below CONFIG values\nREACT_APP_GITHUB_APP_CLIENT_ID REACT_APP_GITHUB_APP_REDIRECT_URI REACT_APP_COMPAGE_APP_SERVER_URL to create it, you will have to use your configurations and create a docker image using below commands (run them from base folder of compage)\nTAG_NAME=\u0026#34;{version you are installing so that it will be automatically taken.}\u0026#34; UI_IMAGE=\u0026#34;ghcr.io/intelops/compage/ui:$TAG_NAME\u0026#34; # Assuming this is the name of your kind cluster CLUSTER_NAME=compage # create docker image for ui docker build -t $UI_IMAGE --network host ui/ kind load docker-image --name $CLUSTER_NAME $UI_IMAGE Once you are done with above commands, kindly run below set of commands.\nhelm repo remove intelops helm repo add \u0026#34;intelops\u0026#34; \u0026#34;https://raw.githubusercontent.com/intelops/compage/main/charts\u0026#34; helm install compage intelops/compage --values charts/compage/values.yaml kubectl get pods -n compage kubectl wait --for=condition=ready pod -l app.kubernetes.io/name=compage-ui kubectl wait --for=condition=ready pod -l app.kubernetes.io/name=compage-core kubectl wait --for=condition=ready pod -l app.kubernetes.io/name=compage-app Go to http://www.mycompage.dev:32222 Uninstall Simply, delete the cluster created above using kind delete cluster --name compage. If that\u0026rsquo;s not possible, delete the namespace kubectl delete ns compage\n"
},{
  "version": "Compage",
  "url": "http://localhost:1313/compage/1.0.0/4-community/",
  "title": "Community",
  "description": "",
  "searchKeyword": "",
  "content": "The Compage by IntelOps community consists of people having industry experience of more than 30 years, we rally around one mission though which is:\nAssist developers in building software with proper set of tools, standards, frameworks, quality, etc. for smoothening developer\u0026rsquo;s workflow by having secured practices in place. Sharing is caring!\nYou can participate and/or contribute to the community.\nDiscord Server For any assistance, please reach out to use on Discord Server, it is an open and inclusive place, you can interact with the maintainers or simply hang out with the community and talk about anything around cloud-native, microservices, security and DevOps.\nCommunity calls We will soon have a few slots open for one-to-one connect with our core-developers. We encourage you to book time with the developers to understand the Compage by IntelOps better or share the idea.\n"
},{
  "version": "Compage",
  "url": "http://localhost:1313/compage/1.0.1/4-community/",
  "title": "Community",
  "description": "",
  "searchKeyword": "",
  "content": "The Compage by IntelOps community consists of people having industry experience of more than 30 years, we rally around one mission though which is:\nAssist developers in building software with proper set of tools, standards, frameworks, quality, etc. for smoothening developer\u0026rsquo;s workflow by having secured practices in place. Sharing is caring!\nYou can participate and/or contribute to the community.\nDiscord Server For any assistance, please reach out to use on Discord Server, it is an open and inclusive place, you can interact with the maintainers or simply hang out with the community and talk about anything around cloud-native, microservices, security and DevOps.\nCommunity calls We will soon have a few slots open for one-to-one connect with our core-developers. We encourage you to book time with the developers to understand the Compage by IntelOps better or share the idea.\n"
},{
  "version": "Compage",
  "url": "http://localhost:1313/compage/1.0.0/5-guides/",
  "title": "User Guide",
  "description": "",
  "searchKeyword": "",
  "content": " How to use Compage Creating MicroServices Declaring Requirements for the Services creation "
},{
  "version": "Compage",
  "url": "http://localhost:1313/compage/1.0.1/5-guides/",
  "title": "User Guide",
  "description": "",
  "searchKeyword": "",
  "content": " How to use Compage Creating MicroServices Declaring Requirements for the Services creation "
},{
  "version": "Compage",
  "url": "http://localhost:1313/compage/1.0.0/6-contribution/",
  "title": "Contribution",
  "description": "",
  "searchKeyword": "",
  "content": "If you are willing to contribute to Compage, kindly follow the guidelines here contributors. Thank you for your contribution!\nContributing to the docs The best way to get started is by reading the \u0026ldquo;Contributor.md\u0026rdquo; along with the Contributor Guidelines.\nThe docs are in the code repository itself under /docs directory. The documentation is created using based on famous framework Docusaurus.\nAfterwards, go ahead and fork the compage repository. Make any changes you want to your fork, and when you\u0026rsquo;re ready to send those changes to us, go to your fork and create a new pull request.\nIf it takes longer than expected to get feedback from the Compage by IntelOps team, head over to the Discord Server and ping a IntelOps staff member either in the #general or #feedback channel, unless you are a member of the private contributor channel. You can always request access to this channel.\nOnce your pull request has been opened, it will be assigned to one or more reviewers. Those reviewers will do a thorough code review, looking for correctness, bugs, opportunities for improvement, documentation, comments, and style.\nMake sure you include relevant updates or additions to documentation when creating or modifying features. Once you’ve received review and approval, your commits are squashed, and your PR is ready for merging.\nCongrats you’re officially a Compage contributor 🎊\nIf you\u0026rsquo;re in need of any assistance at any stage of your contributing journey please don\u0026rsquo;t hesitate to reach out to anybody in the #general or #feedback discord channels, also let us know if you want to be added to the private #contributors channel too. Or directly to @mahendraintelops or @azar-intelops who will always be happy to help.\n"
},{
  "version": "Compage",
  "url": "http://localhost:1313/compage/1.0.1/6-contribution/",
  "title": "Contribution",
  "description": "",
  "searchKeyword": "",
  "content": "If you are willing to contribute to Compage, kindly follow the guidelines here contributors. Thank you for your contribution!\nContributing to the docs The best way to get started is by reading the \u0026ldquo;Contributor.md\u0026rdquo; along with the Contributor Guidelines.\nThe docs are in the code repository itself under /docs directory. The documentation is created using based on famous framework Docusaurus.\nAfterwards, go ahead and fork the compage repository. Make any changes you want to your fork, and when you\u0026rsquo;re ready to send those changes to us, go to your fork and create a new pull request.\nIf it takes longer than expected to get feedback from the Compage by IntelOps team, head over to the Discord Server and ping a IntelOps staff member either in the #general or #feedback channel, unless you are a member of the private contributor channel. You can always request access to this channel.\nOnce your pull request has been opened, it will be assigned to one or more reviewers. Those reviewers will do a thorough code review, looking for correctness, bugs, opportunities for improvement, documentation, comments, and style.\nMake sure you include relevant updates or additions to documentation when creating or modifying features. Once you’ve received review and approval, your commits are squashed, and your PR is ready for merging.\nCongrats you’re officially a Compage contributor 🎊\nIf you\u0026rsquo;re in need of any assistance at any stage of your contributing journey please don\u0026rsquo;t hesitate to reach out to anybody in the #general or #feedback discord channels, also let us know if you want to be added to the private #contributors channel too. Or directly to @mahendraintelops or @azar-intelops who will always be happy to help.\n"
},{
  "version": "Compage",
  "url": "http://localhost:1313/compage/1.0.0/7-telemetry/",
  "title": "Telemetry",
  "description": "",
  "searchKeyword": "",
  "content": "By default, the Compage collects some anonymous usage data. There are two types of data we collect:\nUsage: features usage, we use this data to understand which providers are being used and how much, which helps guide our roadmap and development efforts. Errors: stack traces sent whenever a panic occurs in the core component. Having this data allows us to be notified when there is a bug that needs to be prioritized. We will never: Identify or track users. Collect personal information such as IP addresses, email addresses, or website URLs. Store data about your cloud resources or credentials . Why collect telemetry data? We collect telemetry data for only two reasons:\nIn order to create a better product, we need reliable quantitative information. The data we collect helps us fix bugs, evaluate the success of features, and better understand our users\u0026rsquo; needs.\nWe also need to prove that people are actually using Compage.\nHow to disable data collection Data collection can be disabled at any time by setting a key in values.yaml, then re-installing the Compage instance.\ncore: telemetry: false "
},{
  "version": "Compage",
  "url": "http://localhost:1313/compage/1.0.1/7-telemetry/",
  "title": "Telemetry",
  "description": "",
  "searchKeyword": "",
  "content": "By default, the Compage collects some anonymous usage data. There are two types of data we collect:\nUsage: features usage, we use this data to understand which providers are being used and how much, which helps guide our roadmap and development efforts. Errors: stack traces sent whenever a panic occurs in the core component. Having this data allows us to be notified when there is a bug that needs to be prioritized. We will never: Identify or track users. Collect personal information such as IP addresses, email addresses, or website URLs. Store data about your cloud resources or credentials . Why collect telemetry data? We collect telemetry data for only two reasons:\nIn order to create a better product, we need reliable quantitative information. The data we collect helps us fix bugs, evaluate the success of features, and better understand our users\u0026rsquo; needs.\nWe also need to prove that people are actually using Compage.\nHow to disable data collection Data collection can be disabled at any time by setting a key in values.yaml, then re-installing the Compage instance.\ncore: telemetry: false "
},{
  "version": "Compage",
  "url": "http://localhost:1313/compage/1.0.0/8-faq/",
  "title": "FAQs",
  "description": "",
  "searchKeyword": "",
  "content": "What can Compage help me with? If you are developer and working on microservices, you might have experienced the pain of integrations with latest and trending technologies and tools. There are many scaffolding tools, generators in market and have different way of implementing same stuff. Compage will help you generate the project with the popular integrations.\nIs Compage regularly maintained? Compage is an open-source project that is actively maintained by the IntelOps team. The tool is currently in alpha state and will go in major breaking changes in near future. Join the Discord server so you don\u0026rsquo;t miss any updates.\nHow can I request a new feature? If you would like to request a feature to be added to Compage, feel free to do so through any of the following channels:\nGitHub issues Discord server (#feature-requests channel) Where can I see the upcoming features? We will make a heavy use of GitHub issues. so if you think we should prioritize a certain feature over another, let your voice be heard by up-voting it, we really appreciate your input. Also, let us know if we are missing anything.\nHow can I stay in the loop with new releases? Please check changelog. The best way to find out about the cool features and improvements we\u0026rsquo;ve shipped in the latest releases.\n"
},{
  "version": "Compage",
  "url": "http://localhost:1313/compage/1.0.1/8-faq/",
  "title": "FAQs",
  "description": "",
  "searchKeyword": "",
  "content": "What can Compage help me with? If you are developer and working on microservices, you might have experienced the pain of integrations with latest and trending technologies and tools. There are many scaffolding tools, generators in market and have different way of implementing same stuff. Compage will help you generate the project with the popular integrations.\nIs Compage regularly maintained? Compage is an open-source project that is actively maintained by the IntelOps team. The tool is currently in alpha state and will go in major breaking changes in near future. Join the Discord server so you don\u0026rsquo;t miss any updates.\nHow can I request a new feature? If you would like to request a feature to be added to Compage, feel free to do so through any of the following channels:\nGitHub issues Discord server (#feature-requests channel) Where can I see the upcoming features? We will make a heavy use of GitHub issues. so if you think we should prioritize a certain feature over another, let your voice be heard by up-voting it, we really appreciate your input. Also, let us know if we are missing anything.\nHow can I stay in the loop with new releases? Please check changelog. The best way to find out about the cool features and improvements we\u0026rsquo;ve shipped in the latest releases.\n"
},{
  "version": "Kubviz",
  "url": "http://localhost:1313/kubviz/1.0.1/1-docs-structure/",
  "title": "Docs structure",
  "description": "",
  "searchKeyword": "",
  "content": "\nThis section is a high-level overview of how the KubViz Documentation is structured. It will help you use the documentation more effectively by guiding you on where to look for specific information.\nThe KubViz Documentation covers everything you need to know about KubViz. It made up of four main sections which are:\nGetting started Contributing FAQs Introduction In the introduction section, you will find the three pages below. Head over to the Installation page to get the KubViz up and running on your cluster. The usecase page summarizes the goals and features of the KubViz project.\nWhat is KubViz? Community Installation Contributing KubViz is written in Golang and is Apache License - contributions are always welcome whether that means providing feedback, be it through GitHub, through the #feedback channel on our Discord server or testing existing and new features. All the relevant information below:\nContribute Guides We want to be able to give KubViz users the tips and guidance necessary to be able to get the most value from the tool as quickly as possible. That\u0026rsquo;s why we will be continuously adding and updating informative guides and series in which try to relay valuable and actionable advice.\nFAQs Find all the answers to all the KubViz related questions you might have. Feel free to reach out via the #feedback channel on Discord to request the inclusion of additional questions.\nFAQs "
},{
  "version": "Kubviz",
  "url": "http://localhost:1313/kubviz/1.0.1/3-setup/installation/",
  "title": "Installation",
  "description": "",
  "searchKeyword": "",
  "content": "How KubViz works Kubviz client can be installed on any Kubernetes cluster. Kubviz agent runs in a kubernetes cluster where the changes/events need to be tracked. The agent detects the changes in real time and send those events via NATS JetStream and the same is received in the kubviz client.\nKubviz client receives the events and passes it to Clickhouse database. The events present in the Clickhouse database can be visualized through Grafana.\nKubViz\u0026rsquo;s event tracking component provides comprehensive visibility into the changes and events occurring within your Kubernetes clusters.\nKubViz offers a seamless integration with Git repositories, empowering you to effortlessly track and monitor changes that occur within your codebase. By capturing events such as commits, merges, and other Git activities.\nKubViz also monitors changes in your container registry, providing visibility into image updates. By tracking these changes, KubViz helps you proactively manage container security and compliance.\nHow to install and run Kubviz Prerequisites A Kubernetes cluster Helm binary Prepare Namespace This command will create a new namespace for your cluster.\nkubectl create namespace kubviz Client Installation helm repo add kubviz https://intelops.github.io/kubviz/ helm repo update The following command will generate a token. Please make sure to take note of this token as it will be used for both client and agent installation purposes.\ntoken=$(openssl rand -base64 32 | tr -dc \u0026#39;a-zA-Z0-9\u0026#39; | fold -w 32 | head -n 1) helm upgrade -i kubviz-client kubviz/client -n kubviz --set \u0026#34;nats.auth.token=$token\u0026#34; NOTE:\nIf you want to enable Grafana with the client deployment, add --set grafana.enabled=true to the helm upgrade command.\nIf grafana already exist use the same upgrade command without \u0026ndash;set grafana.enabled=true flag.\nhelm upgrade -i kubviz-client kubviz/client -n kubviz --set \u0026#34;nats.auth.token=$token\u0026#34; --set grafana.enabled=true Parameter Description Default grafana.enabled If true, create grafana false The KubViz client will also install NATS and Clickhouse. The NATS service is exposed as a LoadBalancer, and you need to note the external IP of the service kubviz-client-nats-external and pass it during the KubViz agent installation. The following command will retrieve the IP address. Please make sure to take note of this IP address as it will be used for agent installation if your agent is located in a different cluster.\nkubectl get services kubviz-client-nats-external -n kubviz --output jsonpath=\u0026#39;{.status.loadBalancer.ingress[0].ip}\u0026#39; NOTE:\nKubviz-client pod is in a CrashLoopBackOff state, installing the Kubviz-agent will bring it back up and running. Agent Installation Deploying Agent on the Same Kubernetes Cluster as kubeviz Client: Make sure you have the KubViz client running on your Kubernetes cluster. Run the following command to deploy the KubViz agent: helm upgrade -i kubviz-agent kubviz/agent -n kubviz \\ --set \u0026#34;nats.auth.token=$token\u0026#34; \\ --set git_bridge.enabled=true \\ --set \u0026#34;git_bridge.ingress.hosts[0].host=\u0026lt;INGRESS HOSTNAME\u0026gt;\u0026#34;,git_bridge.ingress.hosts[0].paths[0].path=/,git_bridge.ingress.hosts[0].paths[0].pathType=Prefix,git_bridge.ingress.tls[0].secretName=\u0026lt;SECRET-NAME\u0026gt;,git_bridge.ingress.tls[0].hosts[0]=\u0026lt;INGRESS HOSTNAME\u0026gt; \\ --set container_bridge.enabled=true \\ --set \u0026#34;container_bridge.ingress.hosts[0].host=\u0026lt;INGRESS HOSTNAME\u0026gt;\u0026#34;,container_bridge.ingress.hosts[0].paths[0].path=/,container_bridge.ingress.hosts[0].paths[0].pathType=Prefix,container_bridge.ingress.tls[0].secretName=\u0026lt;SECRET-NAME\u0026gt;,container_bridge.ingress.tls[0].hosts[0]=\u0026lt;INGRESS HOSTNAME\u0026gt; Replace \u0026ldquo;INGRESS HOSTNAME\u0026rdquo; with the desired hostname for the Git Bridge and Container Bridge Ingress configurations. Replace \u0026ldquo;SECRET-NAME\u0026rdquo; with the desired secretname for the Git Bridge and Container Bridge Ingress configurations. Parameter Description Default nats.host nats host kubviz-client-nats git_bridge.enabled If true, create git_bridge false git_bridge.ingress.hosts[0].host git_bridge ingress host name gitbridge.local git_bridge.ingress.hosts[0].paths[0].path git_bridge ingress host path / git_bridge.ingress.hosts[0].paths[0].pathType git_bridge ingress host path type Prefix container_bridge.enabled If true, create container_bridge false container_bridge.ingress.hosts[0].host container_bridge ingress host name containerbridge.local container_bridge.ingress.hosts[0].paths[0].path container_bridge ingress host path / container_bridge.ingress.hosts[0].paths[0].pathType container_bridge ingress host path type Prefix git_bridge.ingress.tls git_bridge ingress tls configuration [] container_bridge.ingress.tls container_bridge ingress tls configuration [] NOTE:\nDefault Annotations for Ingress By default, this Helm chart includes the following annotations for the git bridge and container bridge ingress resource:\nannotations: cert-manager.io/cluster-issuer: letsencrypt-prod-cluster kubernetes.io/force-ssl-redirect: \u0026#34;true\u0026#34; kubernetes.io/ssl-redirect: \u0026#34;true\u0026#34; kubernetes.io/tls-acme: \u0026#34;true\u0026#34; ... If you do not want to use the default value, you can modify the annotation in values.yaml and execute the following command:\nhelm upgrade -i kubviz-agent kubviz/agent -f values.yaml -n kubviz Deploying Agent on a Different Kubernetes Cluster: Run the following command to deploy the KubViz agent: helm upgrade -i kubviz-agent kubviz/agent -n kubviz --set nats.host=\u0026lt;NATS IP Address\u0026gt; --set \u0026#34;nats.auth.token=$token\u0026#34; Replace \u0026ldquo;\u0026rdquo; with the IP address of your NATS service kubviz-client-nats-external. How to Verify if Everything is Up and Running After completing the installation of both the client and agent, you can use the following command to verify if they are up and running.\nkubectl get all -n kubviz Configuration Once everything is up and running, you need to perform additional configurations to monitor git repository events and container registry events.\nTo ensure that these events are sent to KubViz, you need to create a webhook for your repository. This webhook will transmit the event data of the specific repository or registry to KubViz.\nTo set up a webhook in your repository, please follow these steps\nHow to View Event Data in Grafana Retrieve your Grafana login password by running the following command: kubectl get secret --namespace kubviz kubviz-client-grafana -o jsonpath=\u0026#34;{.data.admin-password}\u0026#34; | base64 --decode ; echo Get the Grafana URL to visit by running these commands in the same shell: export POD_NAME=$(kubectl get pods --namespace kubviz -l \u0026#34;app.kubernetes.io/name=grafana,app.kubernetes.io/instance=kubviz-client\u0026#34; -o jsonpath=\u0026#34;{.items[0].metadata.name}\u0026#34;) kubectl --namespace kubviz port-forward $POD_NAME 3000 Access \u0026ldquo;localhost:3000\u0026rdquo; in your web browser, where you\u0026rsquo;ll be prompted to enter your credentials. Utilize the username \u0026ldquo;admin\u0026rdquo; and the password obtained from step 1 to proceed. "
},{
  "version": "Kubviz",
  "url": "http://localhost:1313/kubviz/1.0.1/3-setup/configuration/",
  "title": "Configuration",
  "description": "",
  "searchKeyword": "",
  "content": "Setting Up a Webhook In order to visualize git and container events in Kubviz, it is necessary to create a webhook for the respective repository.\nYou can create a webhook with your own customized data, and in the URL section, you can specify the following format.\nThe URL for a git repository will appear in the following format: https://\u0026lt;INGRESS HOSTNAME\u0026gt;/github Please replace the section with the specific ingress host name of your git bridge, and the path /github may vary depending on the git platform being used.\nPossible values are:\nValues Platform /github GitHub /gitlab GitLab /gitea Gitea /bitbucket BitBucket /azure Azure The URL for a Container Registry will appear in the following format: http://\u0026lt;INGRESS HOSTNAME\u0026gt;/event/docker/hub Please replace the section with the specific ingress host name of your container bridge, and /event/docker/hub may vary depending on the container registry platform being used.\nPossible values are:\nValues Platform /event/docker/hub DockerHub /event/azure/container Azure "
},{
  "version": "Kubviz",
  "url": "http://localhost:1313/kubviz/1.0.1/",
  "title": "KubViz",
  "description": "KubViz User Guide doc",
  "searchKeyword": "",
  "content": ""
},{
  "version": "Kubviz",
  "url": "http://localhost:1313/kubviz/1.0.1/2-overview/",
  "title": "Overview",
  "description": "",
  "searchKeyword": "",
  "content": "\nKubViz is the open-source project by IntelOps.\nVisualize Kubernetes \u0026amp; DevSecOps Workflows. Tracks changes/events real-time across your entire K8s clusters, git repos, container registries, Container image Vulnerability scanning, misconfiguration etc. , analyzing their effects and providing you with the context you need to troubleshoot efficiently. Get the Observability you need, easily.\nProblem Managing Kubernetes and DevSecOps workflows can be complex and challenging. Tracking changes, events, and their impacts across multiple clusters, Git repositories, and container registries can be time-consuming and error-prone. Without proper visibility and context, troubleshooting issues and ensuring system reliability and security becomes difficult.\nSolution: KubViz KubViz addresses these challenges by providing a comprehensive solution for visualizing Kubernetes and DevSecOps workflows. It tracks changes/events in real-time, allowing you to easily analyze their effects and gain the necessary context for efficient troubleshooting. With KubViz, you can overcome the complexity and uncertainty associated with managing these workflows.\nHow KubViz solves the problem: Event Tracking for Clusters KubViz\u0026rsquo;s event tracking component provides comprehensive visibility into the changes and events occurring within your Kubernetes clusters. By installing the KubViz client on any Kubernetes cluster, and deploying the KubViz agent within the cluster where event tracking is required, you can effectively monitor and capture real-time changes. The agent detects these changes in real time and seamlessly sends the events via NATS JetStream to the KubViz client. The KubViz client receives and processes the events, storing them in the ClickHouse database for further analysis and visualization. This robust event tracking mechanism allows you to gain insights into the dynamics of your clusters, understand the impact of changes, and proactively address any issues, ensuring the smooth functioning of your Kubernetes environment.\nGit Bridge for Change Tracking KubViz offers a seamless integration with Git repositories, empowering you to effortlessly track and monitor changes that occur within your codebase. By capturing events such as commits, merges, and other Git activities, KubViz provides valuable insights into the evolution of your code. This comprehensive change tracking capability allows you to analyze the effects of code modifications on your development and deployment workflows, facilitating efficient collaboration among teams. With KubViz\u0026rsquo;s Git bridge, you can easily identify the root causes of issues, ensure code integrity, and maintain a clear understanding of the changes happening within your Git repositories\nContainer Bridge for Registry Changes KubViz\u0026rsquo;s container bridge monitors changes in your container registry, providing visibility into image updates, vulnerability footprints. By tracking these changes, KubViz helps you proactively manage container security and compliance. With a clear understanding of the container landscape, you can mitigate risks, address vulnerabilities, and maintain a robust and secure infrastructure.\nBy combining event tracking, git bridge, and container bridge capabilities, KubViz offers the observability and context needed to streamline your Kubernetes and DevSecOps workflows. With visualizations provided by Grafana, you can easily analyze and optimize your system, ensuring reliable deployments, efficient collaboration, and enhanced overall performance.\nTake control of your Kubernetes and DevSecOps workflows with KubViz and experience the power of real-time tracking and visualization for improved system reliability and security.\nKubernetes Container Security Tracking Using KubViz you can comprehensively scan the kubernetes containers for the security flaws such as vulnerabilities and misconfigurations.\nDetects comprehensive vulnerabilities in OS packages (Alpine, Red Hat Universal Base Image, Red Hat Enterprise Linux, CentOS, Oracle Linux, Debian, Ubuntu, Amazon Linux, openSUSE Leap, SUSE Enterprise Linux, Photon OS and Distroless).\nDetects configuration issues in Kubernetes cluster\nArchitecture "
},{
  "version": "Kubviz",
  "url": "http://localhost:1313/kubviz/1.0.1/3-setup/",
  "title": "Setup",
  "description": "",
  "searchKeyword": "",
  "content": ""
},{
  "version": "Kubviz",
  "url": "http://localhost:1313/kubviz/1.0.1/4-community/",
  "title": "Community",
  "description": "",
  "searchKeyword": "",
  "content": "The KubViz by IntelOps community consists of people having industry experience we rally around one mission though which is:\nSharing is caring!\nYou can participate and/or contribute to the community.\nDiscord Server For any assistance, please reach out to use on Discord Server, it is an open and inclusive place, you can interact with the maintainers.\nCommunity calls We will soon have a few slots open for one-to-one connect with our core-developers. We encourage you to book time with the developers to understand the KubViz by IntelOps better or share the idea.\n"
},{
  "version": "Kubviz",
  "url": "http://localhost:1313/kubviz/1.0.1/5-usecase/",
  "title": "Use Cases",
  "description": "",
  "searchKeyword": "",
  "content": "Cluster Event Tracking Use KubViz to monitor your cluster events, including:\nState changes Errors Other messages that occur in the cluster Visualize Deprecated Kubernetes APIs: KubViz provides a clear visualization of deprecated Kubernetes APIs, allowing users to easily identify and update their usage to comply with the latest Kubernetes versions Track Outdated Images: With KubViz, you can track and monitor outdated images within your clusters, ensuring that you are using the most up-to-date and secure versions. Identify Deleted APIs: KubeViz helps you identify any deleted APIs in your clusters, guiding you to find alternative approaches or replacements to adapt to changes in Kubernetes APIs. Git Repository Events Tracking KubViz allows you to track and observe all the events in your git repository..\nBy capturing events such as commits, merges, and other Git activities, KubViz provides valuable insights into the evolution of your code. This comprehensive change tracking capability allows you to analyze the effects of code modifications on your development and deployment workflows, facilitating efficient collaboration among teams.With this feature, you can easily identify the root causes of issues, ensure code integrity, and maintain a clear understanding of the changes happening within your Git repositories\nContainer Registry Events Tracking Using KubViz you can also monitors changes in your container registry, providing visibility into image updates. By tracking these changes, KubViz helps you proactively manage container registries. Kubernetes Container Security Tracking Using KubViz you can comprehensively scan the kubernetes containers for the security flaws such as vulnerabilities and misconfigurations.\nDetects comprehensive vulnerabilities in OS packages (Alpine, Red Hat Universal Base Image, Red Hat Enterprise Linux, CentOS, Oracle Linux, Debian, Ubuntu, Amazon Linux, openSUSE Leap, SUSE Enterprise Linux, Photon OS and Distroless).\nDetects configuration issues in Kubernetes cluster\n"
},{
  "version": "Kubviz",
  "url": "http://localhost:1313/kubviz/1.0.1/6-contribution/",
  "title": "Contribution",
  "description": "",
  "searchKeyword": "",
  "content": "If you are willing to contribute to KubViz, kindly follow the guidelines here contributors. Thank you for your contribution!\nContributing to the docs The best way to get started is by reading the Contributor Guidelines.\nAfterwards, go ahead and fork the compage repository. Make any changes you want to your fork, and when you\u0026rsquo;re ready to send those changes to us, go to your fork and create a new pull request.\nIf it takes longer than expected to get feedback from the KubViz by IntelOps team, head over to the Discord Server and ping a IntelOps staff member either in the #general or #feedback channel, unless you are a member of the private contributor channel. You can always request access to this channel.\nOnce your pull request has been opened, it will be assigned to one or more reviewers. Those reviewers will do a thorough code review, looking for correctness, bugs, opportunities for improvement, documentation, comments, and style.\nMake sure you include relevant updates or additions to documentation when creating or modifying features. Once you’ve received review and approval, your commits are squashed, and your PR is ready for merging.\nCongrats you’re officially a KubViz contributor 🎊\nIf you\u0026rsquo;re in need of any assistance at any stage of your contributing journey please don\u0026rsquo;t hesitate to reach out to anybody in the #general or #feedback discord channels, also let us know if you want to be added to the private #contributors channel too.\n"
}{
  "version": "Kubviz",
  "url": "http://localhost:1313/kubviz/1.0.1/7-faq/",
  "title": "FAQs",
  "description": "",
  "searchKeyword": "",
  "content": "What can Kubviz help me with? Visualize Kubernetes \u0026amp; DevSecOps Workflows. Tracks changes/events real-time across your entire K8s clusters, git repos, container registries, etc. , analyzing their effects and providing you with the context you need to troubleshoot efficiently. Get the Observability you need, easily.\nIs Kubviz regularly maintained? Kubviz is an open-source project that is actively maintained by the IntelOps team. The tool is currently in alpha state and will go in major breaking changes in near future.\nHow can I request a new feature? If you would like to request a feature to be added to Kubviz, feel free to do so through any of the following channels:\nGitHub issues Where can I see the upcoming features? We will make a heavy use of GitHub issues. so if you think we should prioritize a certain feature over another, let your voice be heard by up-voting it, we really appreciate your input. Also, let us know if we are missing anything.\nHow can I stay in the loop with new releases? Please check changelog. The best way to find out about the cool features and improvements we\u0026rsquo;ve shipped in the latest releases.\n"
},]